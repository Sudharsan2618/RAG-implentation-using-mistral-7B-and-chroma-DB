!pip install langchain sentence-transformers chromadb

from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings
from langchain.vectorstores import chroma

from langchain.llms import HuggingFaceHub
from langchain.chains import RetrievalQA

import os
from getpass import getpass

HF_token = getpass()

os.environ['HuGGINGFACEHUB_API_TOKEN'] =HF_token

URL ="https://docs.google.com/spreadsheets/d/1jQG576TZMhFNSQ2-qu7-oKEjIbODlSVU/edit?usp=sharing&ouid=108080043342042841426&rtpof=true&sd=true"

data = WebBaseLoader(URL)

content = data.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=256,chunk_overlap=0)

chunking = text_splitter.split_documents(content)

embeddings = HuggingFaceInferenceAPIEmbeddings(
    api_key=HF_token,
    model_name="BAAI/bge-base-en-v1.5"
)

from langchain.vectorstores import Chroma

vectorstore = Chroma.from_documents(chunking,embeddings)

model = HuggingFaceHub(repo_id="HuggingFaceH4/mistralai/Mistral-7B-Instruct-v0.2",
                       model_kwargs={"temperature":0.5,"max_new_tokens":512,"max_length":64},
                       huggingfacehub_api_token="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")

retriever = vectorstore.as_retriever(search_type="mmr" ,search_kwargs={"k": 1})

query ="Can you please summarize the personal matters that Sudharsan needs to attend to during his leave"

prompt = f"""

you are an AI Assistant that follows instractions extremely well.
please be truthfull and give direct answers

{query}
"""

qa = RetrievalQA.from_chain_type(llm=model,retriever=retriever,chain_type="stuff")

response = qa(prompt)

print(response['result'])
